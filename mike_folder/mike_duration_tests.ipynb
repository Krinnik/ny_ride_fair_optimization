{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkb\n",
    "from shapely import errors\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import holidays\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../nik_folder/Resources/model_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.columns = df.columns.str.replace(r\"[()',]\", \"\", regex=True).str.strip()\n",
    "df = df.replace({True: 1, False: 0})\n",
    "\n",
    "df.rename(columns={\"fore\": \"fare\"}, inplace=True)\n",
    "df.rename(columns={\"class\": \"service\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"service\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = df[(df[\"service\"] == 0) & (df[\"durationsec\"] > 0)]\n",
    "df_uber = df[(df[\"service\"] == 1) & (df[\"durationsec\"] > 0)]\n",
    "df_lyft = df[(df[\"service\"] == 2) & (df[\"durationsec\"] > 0)]\n",
    "\n",
    "# removing total and fare and for leakage\n",
    "\n",
    "features = [\"second_of_day\", \"day_of_year\", \"PUx\", \"PUy\", \"DOx\", \"DOy\", \"distance\", \"morning_rush\", \"evening rush\",\n",
    "            \"prcp\", \"temp\", \"holiday\", \"weekend\", \"airport\", \"congestion\", \"PU_Bronx\", \"PU_Brooklyn\", \"durationsec\",\n",
    "            \"PU_Manhattan\", \"PU_Queens\", \"PU_Staten Island\", \"DO_Bronx\", \"DO_Brooklyn\", \n",
    "            \"DO_Manhattan\", \"DO_Queens\", \"DO_Staten Island\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "taxi_model = LinearRegression().fit(df_taxi[features], df_taxi[\"fare\"])\n",
    "uber_model = LinearRegression().fit(df_uber[features], df_uber[\"fare\"])\n",
    "lyft_model = LinearRegression().fit(df_lyft[features], df_lyft[\"fare\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# final NaN check\n",
    "df = df.dropna()\n",
    "\n",
    "y = df_taxi[\"durationsec\"] \n",
    "X = df_taxi[features]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb.XGBRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "y_pred_xgb = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MAE: {mae_xgb:.2f}\")\n",
    "r2_via_metric = r2_score(y_test, y_pred_xgb)\n",
    "print(\"R² via r2_score:\", r2_via_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi[\"durationsec\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_uber[\"durationsec\"] \n",
    "X = df_uber[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb.XGBRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "y_pred_xgb = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MAE: {mae_xgb}\")\n",
    "r2_via_metric = r2_score(y_test, y_pred_xgb)\n",
    "print(\"R² via r2_score:\", r2_via_metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_lyft[\"durationsec\"] \n",
    "X = df_lyft[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb.XGBRegressor(random_state=42), param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "y_pred_xgb = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost MAE: {mae_xgb}\")\n",
    "\n",
    "r2_via_metric = r2_score(y_test, y_pred_xgb)\n",
    "print(\"R² via r2_score:\", r2_via_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = random_search\n",
    "i = 1900002\n",
    "test_row = df_uber.iloc[i]\n",
    "test_df = test_row[features].to_frame().T\n",
    "\n",
    "predicted_value = xgb_model.predict(test_df)\n",
    "print(f\"Predicted Value: {predicted_value[0]:.2f}\")\n",
    "print(f\"Actual Value {test_row[\"durationsec\"]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
